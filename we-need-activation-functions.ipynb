{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why we need activation functions\n",
    "\n",
    "Reading: https://www.geeksforgeeks.org/activation-functions-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 1\n",
    "b1 = 7\n",
    "\n",
    "w1 = 2\n",
    "w2 = -1\n",
    "\n",
    "# layer 2\n",
    "b2 =8\n",
    "\n",
    "w3 = 0.2\n",
    "w4 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "x = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1\n",
    "\n",
    "- We multiply the input (x) and the weight for each \"cell\". \n",
    "- Then we add up all of the cells and the bias\n",
    "- We will feed this number to layer 2 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1 = (x * w1) + (x * w2) + b1\n",
    "layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2\n",
    "\n",
    "- Layer 2 takes Layer 1 as input.\n",
    "- Like layer 1, it multiplies the input and the weight for each cell, then adds the bias.\n",
    "- Since it is the last layer, its output is also the output of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the NN: 70.10000000000001\n"
     ]
    }
   ],
   "source": [
    "layer_2 = (layer_1 * w3) + (layer_1 * w4) + b2\n",
    "print(\"Output of the NN:\", layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chained layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_neural_net(x):\n",
    "    layer_1 = (x * w1) + (x * w2) + b1\n",
    "    layer_2 = (layer_1 * w3) + (layer_1 * w4) + b2\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.10000000000001"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_neural_net(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate form for layer 1\n",
    "\n",
    "Here we show how what seemed like 2 parameters it's actually just one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1_weight = w1 + w2\n",
    "layer_1_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1_output = x * layer_1_weight + b1\n",
    "layer_1_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate form for layer 2\n",
    "\n",
    "Again, it's just one parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000000000000004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2_weight = w3 + w4\n",
    "layer_2_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.10000000000001"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2_output = (layer_1_output * layer_2_weight) + b2\n",
    "layer_2_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.10000000000001"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (x * layer_1_weight + b1) * layer_2_weight + b2\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which can be expressed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.10000000000001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (layer_2_weight * layer_1_weight) * x +\n",
    "(layer_2_weight * b1 + b2 )\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's brake down the parts of this equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000000000000004"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weight = (layer_2_weight * layer_1_weight)\n",
    "final_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.100000000000001"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_bias = (layer_2_weight * b1 + b2)\n",
    "final_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.10000000000001"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = final_weight * x + final_bias\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... in the end, the whole neural network was just a linear function! We need to make more transformations if we want the Neural Net to be able to match complex patterns.\n",
    "\n",
    "(Back to slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the RELU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(X, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[relu(i) for i in range(-10, 11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update the neural net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_neural_net_2(x):\n",
    "    layer_1 = relu(x * w1) + relu(x * w2) + b1\n",
    "    layer_2 = relu(layer_1 * w3) + relu(layer_1 * w4) + b2\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.10000000000002"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_neural_net_2(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a \"device\" capable of matching complex patterns if we find the right parameters. But, how do we find them? So far, we chose random numbers! Well, that's exactly how neural nets start: with random parameters. \n",
    "\n",
    "The trick lyas in updating them over and over again so that the network behaves better and better every time.\n",
    "\n",
    "To do that, we first need a way to measure how well the neural net is doing. That's what the Loss function does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "There are many loss functions (https://analyticsindiamag.com/loss-functions-in-deep-learning-an-overview/), and each one of them has its caveats. But in the end, they all compare a predicted value and a true value, and output how close of how far they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(pred, true):\n",
    "    return (pred - true)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y = 420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84042.00999999998"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss score\n",
    "mean_squared_error(layer_2, true_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the random weights, this was the error. Now let's update the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight update\n",
    "\n",
    "The \"learning rate\" will define how big of a \"jump\" we take when updating the weights. A small learning rate will arrive to a precise result... with a lot of iterations. A big learning rate will arrive fast to a good result, but might miss the perfect values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 1\n",
    "b1 = b1 + learning_rate\n",
    "\n",
    "w1 = w1 + learning_rate\n",
    "w2 = w2 + learning_rate\n",
    "\n",
    "# layer 2\n",
    "b2 = b2 + learning_rate\n",
    "\n",
    "w3 = w3 + learning_rate\n",
    "w4 = w4 + learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9753.537599999987"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1 = relu(x * w1) + relu(x * w2) + b1\n",
    "layer_2 = relu(layer_1 * w3) + relu(layer_1 * w4) + b2\n",
    "mean_squared_error(layer_2, true_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error has decreased! We are going in the right direction. Let's update the weights again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 1\n",
    "b1 = b1 + learning_rate\n",
    "\n",
    "w1 = w1 + learning_rate\n",
    "w2 = w2 + learning_rate\n",
    "\n",
    "# layer 2\n",
    "b2 = b2 + learning_rate\n",
    "\n",
    "w3 = w3 + learning_rate\n",
    "w4 = w4 + learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15510.211600000019"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1 = relu(x * w1) + relu(x * w2) + b1\n",
    "layer_2 = relu(layer_1 * w3) + relu(layer_1 * w4) + b2\n",
    "mean_squared_error(layer_2, true_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the error increased. We go back to the parameters we had previously and stay with those. The learning process has ended."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
